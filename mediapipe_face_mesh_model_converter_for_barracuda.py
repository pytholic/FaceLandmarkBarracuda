# -*- coding: utf-8 -*-
"""MediaPipe Face Mesh model converter for Barracuda

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1C6zEB3__gcHEWnWRm-b4jIA0srA1gkyq

# MediaPipe Face Mesh model converter for Unity Barracuda

## What it does

- Converts .tflite into ONNX using tflite2onnx
- Replace Pad operators with combinations of ConstantOfShape and Concat.
- Add Expand operators to PRelu slope inputs.

## Why it's needed

- The current implementation of Barracuda doesn't support non-spatial axis padding, so I had to replace them with concatenation with zero-filled tensors.
- The current implementation of the PRelu activator in Barracuda doesn't support undirectional broadcasting, so I had to expand the slope tensors before feeding to the activators.

# Setup
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install tflite2onnx

"""# tflite to ONNX conversion"""

!wget https://github.com/google/mediapipe/raw/master/mediapipe/models/face_landmark.tflite

!tflite2onnx face_landmark.tflite face_landmark.onnx

"""# Converter implementation"""

import numpy as np
import onnx
from onnx import checker, helper
from onnx import AttributeProto, TensorProto, GraphProto
from onnx import numpy_helper as np_helper

# Shape tensor generator
def get_shape_tensor(model, shape):
  name = 'shape_{0}x{1}x{2}x{3}'.format(*shape)

  # If the initializer already exists, simply use it.
  exists = any(x for x in model.graph.initializer if x.name == name)
  if exists: return name

  # Add the initializer for the tensor.
  tensor = helper.make_tensor(name, TensorProto.INT64, (4,), shape)
  model.graph.initializer.append(tensor)
  return name

"""## Pad operator replacement"""

def replace_pad_ops(model):
  i = 0
  while i < len(model.graph.node):
    # Node type check
    node = model.graph.node[i]
    if node.op_type != 'Pad': i += 1; continue

    # Pad node input
    data = next(n for n in model.graph.value_info  if n.name == node.input[0])
    pads = next(n for n in model.graph.initializer if n.name == node.input[1])

    # Shape tensor
    dim = tuple(map(lambda x: x.dim_value, data.type.tensor_type.shape.dim))
    ext = np_helper.to_array(pads)[5]
    shape_tensor = get_shape_tensor(model, (1, ext, dim[2], dim[3]))

    # Replacement nodes
    const_out = node.name + '_pad'
    const_node = helper.make_node('ConstantOfShape', (shape_tensor,), (const_out,))
    concat_node = helper.make_node('Concat', (data.name, const_out), (node.output[0],), axis = 1)

    # Graph modification
    model.graph.node.insert(i, const_node)
    model.graph.node.insert(i + 1, concat_node)
    model.graph.node.remove(node)
    i += 2

"""## PRelu operator replacement"""

def replace_prelu_ops(model):
  i = 0
  while i < len(model.graph.node):
    # Node type check
    node = model.graph.node[i]
    if node.op_type != 'PRelu': i += 1; continue

    # PRelu node input
    input = next(n for n in model.graph.value_info if n.name == node.input[0])

    # Shape tensor
    dim = tuple(map(lambda x: x.dim_value, input.type.tensor_type.shape.dim))
    shape_tensor = get_shape_tensor(model, dim)

    # Replacement nodes
    expand_out = node.name + '_expand'
    expand_node = helper.make_node('Expand', (node.input[1], shape_tensor), (expand_out,))
    prelu_node = helper.make_node('PRelu', (input.name, expand_out), (node.output[0],))

    # Graph modification
    model.graph.node.insert(i, expand_node)
    model.graph.node.insert(i + 1, prelu_node)
    model.graph.node.remove(node)
    i += 2

"""# ONNX to ONNX (Barracuda) conversion"""

model = onnx.load("face_landmark.onnx")
replace_pad_ops(model)
replace_prelu_ops(model)
checker.check_model(model)
onnx.save(model, "face_landmark_barracuda.onnx")